services:
  postgres:
    image: pgvector/pgvector:pg16
    environment:
      POSTGRES_DB: citespine
      POSTGRES_USER: postgres
      POSTGRES_PASSWORD: postgres
    ports: ["5432:5432"]
    healthcheck:
      test: ["CMD-SHELL", "pg_isready -U postgres -d citespine"]
      interval: 5s
      timeout: 5s
      retries: 20
    volumes:
      - pgdata:/var/lib/postgresql/data

  redis:
    image: redis:7-alpine
    ports: ["6379:6379"]
    command: redis-server --maxmemory 256mb --maxmemory-policy allkeys-lru
    healthcheck:
      test: ["CMD", "redis-cli", "ping"]
      interval: 5s
      timeout: 3s
      retries: 5

  api:
    build:
      context: .
      dockerfile: Dockerfile
    environment:
      PG_DSN: "postgresql+psycopg://postgres:postgres@postgres:5432/citespine"
      VECTOR_BACKEND: "pgvector"
      LLM_PROVIDER: "ollama"
      EMBEDDINGS_PROVIDER: "local"
      AS_OF_DEFAULT: "2023-12-31"
      TOP_K: "10"
      CHUNK_SIZE: "900"
      CHUNK_OVERLAP: "150"
      INVITE_TOKEN: "letmein"
      OFFLINE: "true"
      DEMO_MODE: "true"
      DEMO_RATE_LIMIT_PER_IP: "100/hour"
      # Analysis configuration
      REDIS_URL: "redis://redis:6379/0"
      ANALYSIS_CACHE_TTL: "604800"
      ANALYSIS_MODE: "fast"
      OLLAMA_URL: "http://localhost:11434"
      OLLAMA_MODEL: "llama3"
    volumes:
      - ./:/app
    ports: ["8000:8000"]
    depends_on:
      postgres:
        condition: service_healthy
      redis:
        condition: service_healthy

  k6:
    image: grafana/k6:latest
    profiles: ["perf"]
    depends_on: [api]
    networks: ["default"]
    working_dir: /work
    environment:
      - K6_API_KEY=${K6_API_KEY}
    volumes:
      - ./:/work

volumes:
  pgdata:
